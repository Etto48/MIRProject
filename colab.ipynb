{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook was automatically generated with our custom script (mir.scripts.ipynb_compiler)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multimedia Information Retrieval - Project\n",
                "\n",
                "This project was developed by \"The Karate Kid\" team:\n",
                "\n",
                "- [Ettore Ricci](https://github.com/Etto48)\n",
                "- [Paolo Palumbo](https://github.com/paolpal)\n",
                "- [Zahra Omrani](https://github.com/zahra-omrani)\n",
                "- [Erni Deliallisi](https://github.com/erni-de)\n",
                "\n",
                "The whole codebase can be found on [GitHub](https://github.com/Etto48/MIRProject).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: pandas in /home/erni/.local/lib/python3.10/site-packages (2.2.2)\n",
                        "Requirement already satisfied: tqdm in /home/erni/.local/lib/python3.10/site-packages (4.66.4)\n",
                        "Requirement already satisfied: iprogress in /home/erni/.local/lib/python3.10/site-packages (0.4)\n",
                        "Requirement already satisfied: ipywidgets in /home/erni/.local/lib/python3.10/site-packages (8.1.5)\n",
                        "Requirement already satisfied: unidecode in /home/erni/.local/lib/python3.10/site-packages (1.3.8)\n",
                        "Requirement already satisfied: nltk in /home/erni/.local/lib/python3.10/site-packages (3.9.1)\n",
                        "Requirement already satisfied: more_itertools in /usr/lib/python3/dist-packages (8.10.0)\n",
                        "Requirement already satisfied: python-terrier in /home/erni/.local/lib/python3.10/site-packages (0.12.1)\n",
                        "Requirement already satisfied: torch in /home/erni/.local/lib/python3.10/site-packages (2.5.1)\n",
                        "Requirement already satisfied: transformers in /home/erni/.local/lib/python3.10/site-packages (4.47.0)\n",
                        "Requirement already satisfied: psutil in /home/erni/.local/lib/python3.10/site-packages (5.9.8)\n",
                        "Requirement already satisfied: numpy>=1.22.4 in /home/erni/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/erni/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/erni/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from iprogress) (1.16.0)\n",
                        "Requirement already satisfied: comm>=0.1.3 in /home/erni/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
                        "Requirement already satisfied: ipython>=6.1.0 in /home/erni/.local/lib/python3.10/site-packages (from ipywidgets) (8.24.0)\n",
                        "Requirement already satisfied: traitlets>=4.3.1 in /home/erni/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
                        "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/erni/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
                        "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/erni/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
                        "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
                        "Requirement already satisfied: joblib in /home/erni/.local/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
                        "Requirement already satisfied: regex>=2021.8.3 in /home/erni/.local/lib/python3.10/site-packages (from nltk) (2024.9.11)\n",
                        "Requirement already satisfied: requests in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (2.32.3)\n",
                        "Requirement already satisfied: ir-datasets>=0.3.2 in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (0.5.9)\n",
                        "Requirement already satisfied: wget in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (3.2)\n",
                        "Requirement already satisfied: pyjnius>=1.4.2 in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (1.6.1)\n",
                        "Requirement already satisfied: deprecated in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (1.2.15)\n",
                        "Requirement already satisfied: scipy in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (1.13.0)\n",
                        "Requirement already satisfied: ir-measures>=0.3.1 in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (0.3.6)\n",
                        "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (0.5.6)\n",
                        "Requirement already satisfied: jinja2 in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (3.1.4)\n",
                        "Requirement already satisfied: statsmodels in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (0.14.2)\n",
                        "Requirement already satisfied: dill in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (0.3.8)\n",
                        "Requirement already satisfied: chest in /home/erni/.local/lib/python3.10/site-packages (from python-terrier) (0.2.3)\n",
                        "Requirement already satisfied: filelock in /home/erni/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
                        "Requirement already satisfied: typing-extensions>=4.8.0 in /home/erni/.local/lib/python3.10/site-packages (from torch) (4.11.0)\n",
                        "Requirement already satisfied: networkx in /home/erni/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
                        "Requirement already satisfied: fsspec in /home/erni/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
                        "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
                        "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
                        "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
                        "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/erni/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
                        "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
                        "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/erni/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
                        "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/erni/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
                        "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/erni/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
                        "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
                        "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/erni/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
                        "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
                        "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/erni/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
                        "Requirement already satisfied: triton==3.1.0 in /home/erni/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
                        "Requirement already satisfied: sympy==1.13.1 in /home/erni/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/erni/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
                        "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/erni/.local/lib/python3.10/site-packages (from transformers) (0.26.5)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/erni/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
                        "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/erni/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
                        "Requirement already satisfied: safetensors>=0.4.1 in /home/erni/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
                        "Requirement already satisfied: decorator in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
                        "Requirement already satisfied: jedi>=0.16 in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
                        "Requirement already satisfied: matplotlib-inline in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
                        "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
                        "Requirement already satisfied: pygments>=2.4.0 in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
                        "Requirement already satisfied: stack-data in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
                        "Requirement already satisfied: exceptiongroup in /home/erni/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.1)\n",
                        "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
                        "Requirement already satisfied: beautifulsoup4>=4.4.1 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.3)\n",
                        "Requirement already satisfied: inscriptis>=2.2.0 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.5.0)\n",
                        "Requirement already satisfied: lxml>=4.5.2 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.9.4)\n",
                        "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
                        "Requirement already satisfied: lz4>=3.1.10 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\n",
                        "Requirement already satisfied: warc3-wet>=0.2.3 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
                        "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
                        "Requirement already satisfied: zlib-state>=0.1.3 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.9)\n",
                        "Requirement already satisfied: ijson>=3.1.3 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.3.0)\n",
                        "Requirement already satisfied: unlzw3>=0.2.1 in /home/erni/.local/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in /home/erni/.local/lib/python3.10/site-packages (from requests->python-terrier) (3.3.2)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->python-terrier) (3.3)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->python-terrier) (1.26.5)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /home/erni/.local/lib/python3.10/site-packages (from requests->python-terrier) (2024.8.30)\n",
                        "Requirement already satisfied: heapdict in /home/erni/.local/lib/python3.10/site-packages (from chest->python-terrier) (1.0.1)\n",
                        "Requirement already satisfied: wrapt<2,>=1.10 in /home/erni/.local/lib/python3.10/site-packages (from deprecated->python-terrier) (1.16.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /home/erni/.local/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.5)\n",
                        "Requirement already satisfied: patsy>=0.5.6 in /home/erni/.local/lib/python3.10/site-packages (from statsmodels->python-terrier) (0.5.6)\n",
                        "Requirement already satisfied: soupsieve>1.2 in /home/erni/.local/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/erni/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
                        "Requirement already satisfied: wcwidth in /home/erni/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
                        "Requirement already satisfied: cbor>=1.0.0 in /home/erni/.local/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
                        "Requirement already satisfied: executing>=1.2.0 in /home/erni/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in /home/erni/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
                        "Requirement already satisfied: pure-eval in /home/erni/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "# install dependencies\n",
                "%pip install pandas tqdm iprogress ipywidgets unidecode nltk more_itertools python-terrier torch transformers psutil\n",
                "!git clone https://github.com/facebookresearch/contriever\n",
                "!echo -e '[project]\\nname = \"src\"\\nversion = \"0.1.0\"\\ndescription = \"contriever\"\\ndependencies = [\"beir\", \"torch\", \"transformers\",]\\n\\n[project.license]\\nfile = \"LICENSE\"\\n\\n[tool.setuptools.package-dir]\\nsrc = \"src\"' > contriever/pyproject.toml\n",
                "!pip install -e contriever/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "# define __file__ and set env variable\n",
                "import os\n",
                "__file__ = os.path.abspath('colab.ipynb')\n",
                "os.environ['MIR_NOTEBOOK'] = __file__\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir ===\n",
                "\n",
                "import os\n",
                "import pandas as pd\n",
                "pd.options.mode.copy_on_write = True\n",
                "\n",
                "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
                "    COLAB = True\n",
                "else:\n",
                "    COLAB = False\n",
                "    \n",
                "if COLAB or os.getenv(\"MIR_NOTEBOOK\") is not None:\n",
                "    PROJECT_DIR = os.path.abspath(\"./\")\n",
                "else:\n",
                "    PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
                "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
                "\n",
                "if not os.path.exists(DATA_DIR):\n",
                "    os.mkdir(DATA_DIR)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.document_contents ===\n",
                "\n",
                "\n",
                "\n",
                "class DocumentContents:\n",
                "    def __init__(self, author: str, title: str, body: str, **kwargs):\n",
                "        self.author = author\n",
                "        self.title = title\n",
                "        self.body = body\n",
                "        self.__dict__.update(kwargs)\n",
                "        \n",
                "    def add_field(self, field: str, value: str):\n",
                "        self.__dict__[field] = value\n",
                "        \n",
                "    def set_score(self, score: float):\n",
                "        self.score = score\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.token_ir ===\n",
                "\n",
                "from dataclasses import dataclass\n",
                "from enum import Enum\n",
                "\n",
                "\n",
                "class TokenLocation(Enum) :\n",
                "    QUERY = 0\n",
                "    AUTHOR = 1\n",
                "    TITLE = 2\n",
                "    BODY = 3\n",
                "\n",
                "@dataclass\n",
                "class Token:\n",
                "    text: str\n",
                "    location: TokenLocation\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.tokenizer ===\n",
                "\n",
                "from abc import abstractmethod\n",
                "from typing import Protocol\n",
                "\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.token_ir import Token\n",
                "\n",
                "\n",
                "class Tokenizer(Protocol):\n",
                "    @abstractmethod\n",
                "    def tokenize_query(self, query: str) -> list[Token]:\n",
                "        \"\"\"\n",
                "        Tokenize a query.\n",
                "\n",
                "        # Parameters\n",
                "        - query (str): The query to tokenize.\n",
                "\n",
                "        # Returns\n",
                "        - list[Token]: The tokens of the query.\n",
                "        \"\"\"\n",
                "    @abstractmethod\n",
                "    def tokenize_document(self, doc: DocumentContents) -> list[Token]:\n",
                "        \"\"\"\n",
                "        Tokenize a document.\n",
                "\n",
                "        # Parameters\n",
                "        - doc (DocumentContents): The document to tokenize.\n",
                "\n",
                "        # Returns\n",
                "        - list[Token]: The tokens of the document.\n",
                "        \"\"\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.document_info ===\n",
                "\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.token_ir import TokenLocation\n",
                "# from mir.ir.tokenizer import Tokenizer\n",
                "\n",
                "\n",
                "class DocumentInfo:\n",
                "    def __init__(self, id: int, lengths: list[int]):\n",
                "        assert len(lengths) == 3, \"Lengths must have 3 elements, [author, title, body]\"\n",
                "        self.id = id\n",
                "        self.lengths = lengths\n",
                "\n",
                "    @staticmethod\n",
                "    def from_document_contents(id: int, doc: DocumentContents, tokenizer: Tokenizer) -> \"DocumentInfo\":\n",
                "        tokens = tokenizer.tokenize_document(doc)\n",
                "        tokens_for_field = [0,0,0]\n",
                "        for token in tokens:\n",
                "            match token.location:\n",
                "                case TokenLocation.AUTHOR:\n",
                "                    field_offset = 0\n",
                "                case TokenLocation.TITLE:\n",
                "                    field_offset = 1\n",
                "                case TokenLocation.BODY:\n",
                "                    field_offset = 2\n",
                "                case _:\n",
                "                    raise ValueError(f\"Invalid token location {token.location}\")\n",
                "            tokens_for_field[field_offset] += 1\n",
                "        return DocumentInfo(id, tokens_for_field)        \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.posting ===\n",
                "\n",
                "from typing import Optional\n",
                "\n",
                "class Posting:\n",
                "    def __init__(self, doc_id: int, term_id: int, occurrences: Optional[dict[str, int]] = None):\n",
                "        self.term_id = term_id\n",
                "        self.doc_id = doc_id\n",
                "        self.occurrences = occurrences if occurrences is not None else {\"author\": 0, \"title\": 0, \"body\": 0}\n",
                "\n",
                "    def __repr__(self) -> str:\n",
                "        return f\"Posting(doc_id={self.doc_id}, term_id={self.term_id}, occurrences={self.occurrences})\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.term ===\n",
                "\n",
                "class Term:\n",
                "    def __init__(self, term: str, id: int, **kwargs):\n",
                "        self.term = term\n",
                "        self.id = id\n",
                "        self.info = kwargs\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.scoring_function ===\n",
                "\n",
                "from typing import Any, Callable, Optional, Protocol\n",
                "\n",
                "# from mir.ir.document_info import DocumentInfo\n",
                "# from mir.ir.posting import Posting\n",
                "# from mir.ir.term import Term\n",
                "\n",
                "\n",
                "class ScoringFunction(Protocol):\n",
                "    batched_call: Optional[Callable[[\"ScoringFunction\",list[str],str], list[float]]] = None\n",
                "    def __call__(self, document_info: DocumentInfo, postings: list[Posting], query: list[Term], **kwargs: dict[str, Any]) -> float:\n",
                "        \"\"\"\n",
                "        Score a document based on the postings and the query.\n",
                "\n",
                "        # Parameters\n",
                "        - document_info (DocumentInfo): The document info relative to the document to score.\n",
                "        - postings (list[Posting]): The postings related to the document and the query.\n",
                "        - query (list[Term]): The query terms.\n",
                "        - **kwargs (dict[str, Any]): Additional arguments for the scoring function.\n",
                "\n",
                "        # Returns\n",
                "        - float: The score of the document.\n",
                "        \"\"\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.impls.bm25f_scoring ===\n",
                "\n",
                "from typing import List, Dict\n",
                "# from mir.ir.document_info import DocumentInfo\n",
                "# from mir.ir.posting import Posting\n",
                "# from mir.ir.scoring_function import ScoringFunction\n",
                "# from mir.ir.term import Term\n",
                "import math\n",
                "\n",
                "\n",
                "class BM25FScoringFunction(ScoringFunction):\n",
                "    def __init__(self, k1: float = 1.5, b: float = 0.75, field_weights: Dict[str, float] = None):\n",
                "        self.k1 = k1\n",
                "        self.b = b\n",
                "        self.field_weights = field_weights if field_weights is not None else {'title': 2.0, 'body': 1.0, 'author': 0.5}\n",
                "\n",
                "    def _build_postings_dict(self, postings: List[Posting]) -> Dict[int, Posting]:\n",
                "        return {posting.term_id: posting for posting in postings}\n",
                "\n",
                "    def __call__(self, document: DocumentInfo, postings: List[Posting], query: List[Term], *, num_docs: int, avg_field_lengths: dict[str, int], **_) -> float:\n",
                "        postings_dict = self._build_postings_dict(postings)\n",
                "        score = 0.0\n",
                "        for term in query:\n",
                "            if term.id in postings_dict:\n",
                "                score += self._rsv(term, document, num_docs, postings_dict, avg_field_lengths)\n",
                "        return score\n",
                "\n",
                "    def _rsv(self, term: Term, document: DocumentInfo, num_docs: int, postings_dict: dict[int, Posting], avg_field_lengths: dict[str, int]) -> float:\n",
                "        tfd = self._wtf(term, document, postings_dict, avg_field_lengths)\n",
                "        idf = math.log(num_docs / term.info['document_frequency'])\n",
                "\n",
                "        if tfd > 0:\n",
                "            return (tfd / (self.k1 + tfd)) * idf\n",
                "        return 0.0\n",
                "\n",
                "    def _wtf(self, term: Term, document: DocumentInfo, postings_dict: dict[int, Posting], avg_field_lengths: dict[str, int]) -> float:\n",
                "        tfd = 0.0\n",
                "        field_indices = {\"author\": 0, \"title\": 1, \"body\": 2}\n",
                "\n",
                "        if term.id not in postings_dict:\n",
                "            return 0.0\n",
                "\n",
                "        posting = postings_dict[term.id]\n",
                "        for field, weight in self.field_weights.items():\n",
                "            tf = posting.occurrences.get(field, 0)\n",
                "            if tf == 0:\n",
                "                continue\n",
                "            field_index = field_indices[field]\n",
                "            avg_dlf = avg_field_lengths[field]\n",
                "            bb = 1 - self.b + self.b * document.lengths[field_index] / avg_dlf\n",
                "            tfd += weight * tf / bb\n",
                "\n",
                "        return tfd\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.impls.count_scoring_function ===\n",
                "\n",
                "# from mir.ir.scoring_function import ScoringFunction\n",
                "\n",
                "\n",
                "class CountScoringFunction(ScoringFunction):\n",
                "    def __call__(self, document, postings, query, **kwargs):\n",
                "        return len(postings) / len(query)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.utils.sized_generator ===\n",
                "\n",
                "from collections.abc import Generator, Sized\n",
                "from typing import TypeVar, Generic\n",
                "\n",
                "T = TypeVar('T')\n",
                "P = TypeVar('P')\n",
                "Q = TypeVar('Q')\n",
                "\n",
                "\n",
                "class SizedGenerator(Generic[T, P, Q], Generator[T, P, Q], Sized):\n",
                "    def __init__(self, generator: Generator[T, P, Q], length: int):\n",
                "        self.generator = generator\n",
                "        self.length = length\n",
                "\n",
                "    def __iter__(self):\n",
                "        return self.generator\n",
                "\n",
                "    def __len__(self):\n",
                "        return self.length\n",
                "\n",
                "    def send(self, value):\n",
                "        return self.generator.send(value)\n",
                "\n",
                "    def throw(self, typ, val=None, tb=None):\n",
                "        return self.generator.throw(typ, val, tb)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Index\n",
                "\n",
                "This interface is the component that actually holds the inverted index and exposes the methods to interact with it.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.index ===\n",
                "\n",
                "from abc import abstractmethod\n",
                "from collections.abc import Generator\n",
                "from typing import Any, Optional, Protocol\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# from mir.ir.document_info import DocumentInfo\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.posting import Posting\n",
                "# from mir.ir.term import Term\n",
                "# from mir.ir.tokenizer import Tokenizer\n",
                "# from mir.utils.sized_generator import SizedGenerator\n",
                "\n",
                "\n",
                "class Index(Protocol):\n",
                "    def get_global_info(self) -> dict[str, Any]:\n",
                "        \"\"\"\n",
                "        Get global info from the index.\n",
                "\n",
                "        # Returns\n",
                "        - dict[str, int]: A dictionary with global info.\n",
                "        \"\"\"\n",
                "        return {}\n",
                "\n",
                "    @abstractmethod\n",
                "    def get_postings(self, term_id: int) -> Generator[Posting, None, None]:\n",
                "        \"\"\"\n",
                "        Get a generator of postings for a term_id.\n",
                "        MUST be sorted by doc_id.\n",
                "\n",
                "        # Parameters\n",
                "        - term_id (int): The term_id.\n",
                "\n",
                "        # Yields\n",
                "        - Posting: A posting from the posting list related to the term_id.\n",
                "        \"\"\"\n",
                "\n",
                "    @abstractmethod\n",
                "    def get_document_info(self, doc_id: int) -> DocumentInfo:\n",
                "        \"\"\"\n",
                "        Get document info from a doc_id.\n",
                "\n",
                "        # Parameters\n",
                "        - doc_id (int): The doc_id.\n",
                "\n",
                "        # Returns\n",
                "        - DocumentInfo: The document info related to the doc_id.\n",
                "        \"\"\"\n",
                "    \n",
                "    def get_document_contents(self, doc_id: int) -> DocumentContents:\n",
                "        \"\"\"\n",
                "        Get document contents from a doc_id.\n",
                "\n",
                "        # Parameters\n",
                "        - doc_id (int): The doc_id.\n",
                "\n",
                "        # Returns\n",
                "        - DocumentContents: The document contents related to the doc_id.\n",
                "        \"\"\"\n",
                "\n",
                "    @abstractmethod\n",
                "    def get_term(self, term_id: int) -> Term:\n",
                "        \"\"\"\n",
                "        Get term info from a term_id.\n",
                "\n",
                "        # Parameters\n",
                "        - term_id (int): The term_id.\n",
                "\n",
                "        # Returns\n",
                "        - Term: The term related to the term_id.\n",
                "        \"\"\"\n",
                "\n",
                "    @abstractmethod\n",
                "    def get_term_id(self, term: str) -> Optional[int]:\n",
                "        \"\"\"\n",
                "        Get term_id from a term in string format.\n",
                "        Returns None if the term is not in the index.\n",
                "\n",
                "        # Parameters\n",
                "        - term (str): The term in string format.\n",
                "\n",
                "        # Returns\n",
                "        - Optional[int]: The term_id related to the term or None if the term is not in the index.\n",
                "        \"\"\"\n",
                "\n",
                "    @abstractmethod\n",
                "    def __len__(self) -> int:\n",
                "        \"\"\"\n",
                "        Get the number of documents in the index.\n",
                "\n",
                "        # Returns\n",
                "        - int: The number of documents in the index.\n",
                "        \"\"\"\n",
                "\n",
                "    @abstractmethod\n",
                "    def index_document(self, doc: DocumentContents, tokenizer: Tokenizer) -> None:\n",
                "        \"\"\"\n",
                "        Add a document to the index.\n",
                "\n",
                "        # Parameters\n",
                "        - doc (DocumentContents): The document to add to the index.\n",
                "        - tokenizer (Tokenizer): The tokenizer to use to tokenize the document.\n",
                "        \"\"\"\n",
                "\n",
                "    def bulk_index_documents(self, docs: SizedGenerator[DocumentContents, None, None], tokenizer: Tokenizer, verbose: bool = False) -> None:\n",
                "        \"\"\"\n",
                "        Add multiple documents to the index, this calls index_document for each document.\n",
                "\n",
                "        # Parameters\n",
                "        - docs (SizedGenerator[DocumentContents, None, None]): A generator of documents to add to the index.\n",
                "        - tokenizer (Tokenizer): The tokenizer to use to tokenize the documents.\n",
                "        - verbose (bool): Whether to show a progress bar.\n",
                "        \"\"\"        \n",
                "        for doc in tqdm(docs, desc=\"Indexing documents\", disable=not verbose, total=len(docs)):\n",
                "            self.index_document(doc, tokenizer)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.impls.default_index ===\n",
                "\n",
                "from collections import OrderedDict\n",
                "from collections.abc import Generator\n",
                "# import os\n",
                "import pickle\n",
                "from typing import Any, Optional\n",
                "# from mir.ir.document_info import DocumentInfo\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.index import Index\n",
                "# from mir.ir.posting import Posting\n",
                "# from mir.ir.term import Term\n",
                "# from mir.ir.token_ir import TokenLocation\n",
                "# from mir.ir.tokenizer import Tokenizer\n",
                "# from mir.utils.sized_generator import SizedGenerator\n",
                "\n",
                "\n",
                "class DefaultIndex(Index):\n",
                "    def __init__(self, path: Optional[str] = None):\n",
                "        super().__init__()\n",
                "        self.postings: list[OrderedDict[Posting]] = []\n",
                "        self.document_info: list[DocumentInfo] = []\n",
                "        self.document_contents: list[DocumentContents] = []\n",
                "        self.terms: list[Term] = []\n",
                "        self.term_lookup: dict[str, int] = {}\n",
                "        self.path = None\n",
                "        self.total_field_lengths = {\n",
                "            \"author\": 0,\n",
                "            \"title\": 0,\n",
                "            \"body\": 0\n",
                "        }\n",
                "        if path is not None:\n",
                "            self.path = path\n",
                "            if os.path.exists(path):\n",
                "                self.load()\n",
                "    \n",
                "    def get_postings(self, term_id: int) -> Generator[Posting, None, None]:\n",
                "        for doc_id, posting in self.postings[term_id].items():\n",
                "            yield posting\n",
                "\n",
                "    def get_document_info(self, doc_id: int) -> DocumentInfo:\n",
                "        return self.document_info[doc_id]\n",
                "    \n",
                "    def get_document_contents(self, doc_id: int) -> DocumentContents:\n",
                "        return self.document_contents[doc_id]\n",
                "\n",
                "    def get_term(self, term_id: int) -> Term:\n",
                "        return self.terms[term_id]\n",
                "\n",
                "    def get_term_id(self, term: str) -> Optional[int]:\n",
                "        return self.term_lookup.get(term)\n",
                "    \n",
                "    def get_global_info(self) -> dict[str, Any]:\n",
                "        return {\n",
                "            \"avg_field_lengths\": {\n",
                "                \"author\": self.total_field_lengths[\"author\"] / len(self.document_info),\n",
                "                \"title\": self.total_field_lengths[\"title\"] / len(self.document_info),\n",
                "                \"body\": self.total_field_lengths[\"body\"] / len(self.document_info)\n",
                "            },\n",
                "            \"num_docs\": len(self.document_info)\n",
                "        }\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        return len(self.document_info)\n",
                "\n",
                "    def index_document(self, doc: DocumentContents, tokenizer: Tokenizer) -> None:\n",
                "        terms = tokenizer.tokenize_document(doc)\n",
                "        author_length = sum(1 for term in terms if term.location == TokenLocation.AUTHOR)\n",
                "        title_length = sum(1 for term in terms if term.location == TokenLocation.TITLE)\n",
                "        body_length = sum(1 for term in terms if term.location == TokenLocation.BODY)\n",
                "        self.total_field_lengths[\"author\"] += author_length\n",
                "        self.total_field_lengths[\"title\"] += title_length\n",
                "        self.total_field_lengths[\"body\"] += body_length\n",
                "        term_ids = []\n",
                "        for term in terms:\n",
                "            if term.text not in self.term_lookup:\n",
                "                term_id = len(self.terms)\n",
                "                self.terms.append(Term(term.text, term_id))\n",
                "                self.term_lookup[term.text] = term_id\n",
                "            else:\n",
                "                term_id = self.term_lookup[term.text]\n",
                "            term_ids.append(term_id)\n",
                "        doc_id = len(self.document_info)\n",
                "        self.document_info.append(DocumentInfo.from_document_contents(doc_id, doc, tokenizer))\n",
                "        self.document_contents.append(doc)\n",
                "        for term_id in term_ids:\n",
                "            if term_id >= len(self.postings):\n",
                "                self.postings.append(OrderedDict())\n",
                "            self.postings[term_id][doc_id] = Posting(doc_id, term_id)\n",
                "\n",
                "    def bulk_index_documents(self, docs: SizedGenerator[DocumentContents, None, None], tokenizer: Tokenizer, verbose: bool = False) -> None:\n",
                "        super().bulk_index_documents(docs, tokenizer, verbose)\n",
                "        if self.path is not None:\n",
                "            self.save()\n",
                "\n",
                "    def load(self):\n",
                "        if self.path is not None:\n",
                "            try:\n",
                "                with open(self.path, \"rb\") as f:\n",
                "                    postings, document_info, document_contents, terms, term_lookup = pickle.load(f)\n",
                "                assert isinstance(postings, list)\n",
                "                assert isinstance(document_info, list)\n",
                "                assert isinstance(document_contents, list)\n",
                "                assert isinstance(terms, list)\n",
                "                assert isinstance(term_lookup, dict)\n",
                "            except Exception as e:\n",
                "                pass\n",
                "            else:\n",
                "                self.postings = postings\n",
                "                self.document_info = document_info\n",
                "                self.document_contents = document_contents\n",
                "                self.terms = terms\n",
                "                self.term_lookup = term_lookup\n",
                "        else:\n",
                "            raise ValueError(\"Path not set for index.\")\n",
                "\n",
                "    def save(self):\n",
                "        if self.path is not None:\n",
                "            with open(self.path, \"wb\") as f:\n",
                "                pickle.dump((self.postings, self.document_info, self.document_contents, self.terms, self.term_lookup), f)\n",
                "        else:\n",
                "            raise ValueError(\"Path not set for index.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.impls.default_tokenizers ===\n",
                "\n",
                "import string\n",
                "import nltk\n",
                "import nltk.corpus\n",
                "import unidecode\n",
                "# from mir import DATA_DIR\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.tokenizer import Tokenizer\n",
                "# from mir.ir.token_ir import Token, TokenLocation\n",
                "\n",
                "\n",
                "class DefaultTokenizer(Tokenizer):\n",
                "    def __init__(self):\n",
                "        download_dir = f\"{DATA_DIR}/nltk_data\"\n",
                "        nltk.download(\"stopwords\", quiet=True, download_dir=download_dir,)\n",
                "        stopwords_from_path = nltk.data.find(\"corpora/stopwords/english\", [download_dir])\n",
                "        with open(stopwords_from_path) as f:\n",
                "            self.stopwords = frozenset(f.read().splitlines())\n",
                "        \n",
                "        self.stemmer = nltk.SnowballStemmer(\"english\")\n",
                "        self.remove_punctuation = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
                "        self.separate_numbers = str.maketrans({key: f\" {key} \" for key in string.digits})\n",
                "    \n",
                "    def preprocess(self, text: str):\n",
                "        # normalize unicode\n",
                "        text = unidecode.unidecode(text, errors=\"replace\", replace_str=\" \")\n",
                "        # replace punctuation with space\n",
                "        text = text.translate(self.remove_punctuation).lower()\n",
                "        # separate numbers with a space\n",
                "        text = text.translate(self.separate_numbers)\n",
                "        # split text into words\n",
                "        words = text.split()\n",
                "        # remove stopwords\n",
                "        words = [word for word in words if word not in self.stopwords]\n",
                "        # stem words\n",
                "        words: list[str] = [self.stemmer.stem(word) for word in words]\n",
                "        return words\n",
                "\n",
                "\n",
                "    def tokenize_query(self, query: str) -> list[Token]:\n",
                "        query_list = self.preprocess(query)\n",
                "        token_list = [Token(word, TokenLocation.QUERY) for word in query_list]\n",
                "        \n",
                "        return token_list\n",
                "\n",
                "    def tokenize_document(self, doc: DocumentContents) -> list[Token]:\n",
                "        author_list = self.preprocess(doc.author)\n",
                "        title_list = self.preprocess(doc.title)\n",
                "        body_list = self.preprocess(doc.body)\n",
                "        \n",
                "        token_list = \\\n",
                "            [Token(aword, TokenLocation.AUTHOR) for aword in author_list] + \\\n",
                "            [Token(tword, TokenLocation.TITLE) for tword in title_list] + \\\n",
                "            [Token(bword, TokenLocation.BODY) for bword in body_list]\n",
                "        \n",
                "        return token_list\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.neural_relevance.dataset ===\n",
                "\n",
                "from typing import Literal\n",
                "import torch\n",
                "from torch import nn\n",
                "# import pandas as pd\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# from mir import DATA_DIR\n",
                "\n",
                "class MSMarcoDataset(torch.utils.data.Dataset):\n",
                "    def __init__(self, collection_path: str, queries_path: str, qrels_path: str):\n",
                "        self.collection = self.load_collection(collection_path)\n",
                "        self.queries = self.load_queries(queries_path)\n",
                "        self.qrels = self.load_qrels(qrels_path)\n",
                "\n",
                "    @staticmethod\n",
                "    def load(mode: Literal[\"train\", \"valid\", \"test\"]):\n",
                "        collection_path = f\"{DATA_DIR}/msmarco/collection.tsv\"\n",
                "        match mode:\n",
                "            case \"train\":\n",
                "                queries_path = f\"{DATA_DIR}/msmarco/queries.train.tsv\"\n",
                "                qrels_path = f\"{DATA_DIR}/msmarco/qrels.train.tsv\"\n",
                "            case \"valid\":\n",
                "                queries_path = f\"{DATA_DIR}/msmarco/msmarco-test2019-queries.tsv\"\n",
                "                qrels_path = f\"{DATA_DIR}/msmarco/2019qrels-pass.txt\"\n",
                "            case \"test\":\n",
                "                raise NotImplementedError(f\"Mode {mode} not implemented.\")\n",
                "            case _:\n",
                "                raise ValueError(f\"Invalid mode {mode}.\")\n",
                "        return MSMarcoDataset(collection_path, queries_path, qrels_path)\n",
                "\n",
                "    def load_collection(self, collection_path: str):\n",
                "        collection = pd.read_csv(collection_path, sep='\\t', header=None, names=['docid', 'text'], index_col='docid')\n",
                "        return collection\n",
                "    \n",
                "    def load_queries(self, queries_path: str):\n",
                "        queries = pd.read_csv(queries_path, sep='\\t', header=None, names=['qid', 'text'], index_col='qid')\n",
                "        return queries\n",
                "    \n",
                "    def load_qrels(self, qrels_path: str):\n",
                "        sep = ' ' if qrels_path.endswith(\".txt\") else '\\t'\n",
                "        qrels = pd.read_csv(qrels_path, sep=sep, header=None, names=['qid', 'Q0', 'docid', 'relevance'])\n",
                "        return qrels\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.qrels)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        qid = self.qrels.iloc[idx]['qid']\n",
                "        docid = self.qrels.iloc[idx]['docid']\n",
                "        relevance = self.qrels.iloc[idx]['relevance']\n",
                "        query = self.queries.loc[qid]['text']\n",
                "        doc = self.collection.loc[docid]['text']\n",
                "        return query, doc, relevance\n",
                "    \n",
                "    @staticmethod\n",
                "    def collate_fn(batch):\n",
                "        queries, docs, relevances = zip(*batch)\n",
                "        return queries, docs, torch.tensor(relevances, dtype=torch.float32)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at facebook/contriever-msmarco were not used when initializing Contriever: ['pooler.dense.bias', 'pooler.dense.weight']\n",
                        "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
                    ]
                }
            ],
            "source": [
                "# import os\n",
                "import requests\n",
                "# import torch\n",
                "from torch import nn\n",
                "from tqdm.auto import tqdm\n",
                "import transformers\n",
                "from src.contriever import Contriever\n",
                "\n",
                "contriever_ = Contriever.from_pretrained(\"facebook/contriever-msmarco\")\n",
                "tokenizer = transformers.AutoTokenizer.from_pretrained(\"facebook/contriever-msmarco\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.neural_relevance.model ===\n",
                "\n",
                "# import os\n",
                "import requests\n",
                "#import torch\n",
                "from torch import nn\n",
                "from tqdm.auto import tqdm\n",
                "import transformers\n",
                "\n",
                "# from mir import DATA_DIR\n",
                "# from mir.neural_relevance.dataset import MSMarcoDataset\n",
                "\n",
                "class NeuralRelevance(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.device = torch.device(\n",
                "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "        \n",
                "        model_name = \"bert-large-uncased\"\n",
                "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\"facebook/contriever-msmarco\")\n",
                "        self.model = Contriever.from_pretrained(\"facebook/contriever-msmarco\").to(self.device)\n",
                "        for param in self.model.parameters():\n",
                "            param.requires_grad = False\n",
                "        \n",
                "        bert_embedding_size = self.model.config.hidden_size\n",
                "        self.similairty_head = nn.Sequential(\n",
                "            nn.Linear(bert_embedding_size, 1, device=self.device),\n",
                "            nn.Sigmoid()\n",
                "        ).to(self.device)\n",
                "        \n",
                "\n",
                "    def forward(self, x: dict) -> torch.Tensor:\n",
                "        x = self.model(**x).last_hidden_state\n",
                "        features = x[:, 0, :]\n",
                "        x = self.similairty_head(features)\n",
                "        return x.squeeze()\n",
                "\n",
                "    def preprocess(self, queries: list[str], documents: list[str]) -> dict:\n",
                "        tokens = self.tokenizer(queries, documents, return_tensors=\"pt\", padding=True).to(self.device)\n",
                "        return tokens\n",
                "\n",
                "    def forward_queries_and_documents(self, queries: list[str], documents: list[str]) -> torch.Tensor:\n",
                "        x = self.preprocess(queries, documents)\n",
                "        return self.forward(x)\n",
                "\n",
                "    def loss(\n",
                "        self,\n",
                "        similarity: torch.Tensor,\n",
                "        relevance: torch.Tensor,\n",
                "    ):\n",
                "        ce_similarity_loss = torch.nn.functional.binary_cross_entropy(similarity, relevance / 5)\n",
                "        mse_similarity_loss = torch.nn.functional.mse_loss(similarity, relevance / 5)\n",
                "        return ce_similarity_loss, mse_similarity_loss, ce_similarity_loss\n",
                "\n",
                "    def fit(self, train: MSMarcoDataset, valid: MSMarcoDataset, epochs: int = 100):\n",
                "        bs = 16\n",
                "        train_loader = torch.utils.data.DataLoader(\n",
                "            train,\n",
                "            batch_size=bs,\n",
                "            collate_fn=MSMarcoDataset.collate_fn,\n",
                "            sampler=torch.utils.data.RandomSampler(\n",
                "                train, replacement=True, num_samples=bs * 100)\n",
                "        )\n",
                "        valid_loader = torch.utils.data.DataLoader(\n",
                "            valid,\n",
                "            batch_size=bs,\n",
                "            collate_fn=MSMarcoDataset.collate_fn,\n",
                "            sampler=torch.utils.data.RandomSampler(\n",
                "                valid, replacement=True, num_samples=bs * 50)\n",
                "        )\n",
                "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, weight_decay=1)\n",
                "        best_loss = float(\"inf\")\n",
                "        best_model = None\n",
                "        patience = 3\n",
                "        threshold = 0.001\n",
                "        epochs_without_improvement = 0\n",
                "\n",
                "        history = {\n",
                "            \"train_ce\": [], \"valid_ce\": [],\n",
                "            \"train_mse\": [], \"valid_mse\": [],\n",
                "        }\n",
                "\n",
                "        for epoch in range(epochs):\n",
                "            self.train()\n",
                "            avg_ce = 0\n",
                "            avg_mse = 0\n",
                "            batches = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} (train)\", total=len(train_loader))\n",
                "            for i, (queries, docs, relevances) in enumerate(batches):\n",
                "                relevances = relevances.to(self.device)\n",
                "                optimizer.zero_grad()\n",
                "                similarity = self.forward_queries_and_documents(queries, docs)\n",
                "                ce, mse, loss = self.loss(similarity, relevances)\n",
                "                avg_ce += ce.item()\n",
                "                avg_mse += mse.item()\n",
                "                batches.set_postfix(\n",
                "                    ce=avg_ce / (i + 1), \n",
                "                    mse=avg_mse / (i + 1))\n",
                "                loss.backward()\n",
                "                torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
                "                optimizer.step()\n",
                "            avg_ce /= (i + 1)\n",
                "            avg_mse /= (i + 1)\n",
                "            history[\"train_ce\"].append(avg_ce)\n",
                "            history[\"train_mse\"].append(avg_mse)\n",
                "            self.eval()\n",
                "            with torch.no_grad():\n",
                "                avg_ce = 0\n",
                "                avg_mse = 0\n",
                "                avg_loss = 0\n",
                "                batches = tqdm(valid_loader, desc=f\"Epoch {epoch + 1}/{epochs} (valid)\", total=len(valid_loader))\n",
                "                for i, (queries, docs, relevances) in enumerate(batches):\n",
                "                    relevances = relevances.to(self.device)\n",
                "                    similarity = self.forward_queries_and_documents(queries, docs)\n",
                "                    ce, mse, loss = self.loss(similarity, relevances)\n",
                "                    avg_ce += ce.item()\n",
                "                    avg_mse += mse.item()\n",
                "                    avg_loss += loss.item()\n",
                "                    batches.set_postfix(\n",
                "                        ce=avg_ce / (i + 1),\n",
                "                        mse=avg_mse / (i + 1))\n",
                "                avg_ce /= (i + 1)\n",
                "                avg_mse /= (i + 1)\n",
                "                history[\"valid_ce\"].append(avg_ce)\n",
                "                history[\"valid_mse\"].append(avg_mse)\n",
                "                if avg_loss < best_loss - threshold:\n",
                "                    best_loss = avg_loss\n",
                "                    best_model = self.state_dict()\n",
                "                    epochs_without_improvement = 0\n",
                "                else:\n",
                "                    epochs_without_improvement += 1\n",
                "                    if epochs_without_improvement >= patience:\n",
                "                        break\n",
                "        self.load_state_dict(best_model)\n",
                "        return history\n",
                "    \n",
                "    def save(self, path: str):\n",
                "        torch.save(self.state_dict(), path)\n",
                "    \n",
                "    @staticmethod\n",
                "    def load(path: str):\n",
                "        model = NeuralRelevance()\n",
                "        model.load_state_dict(torch.load(path, map_location=model.device, weights_only=True))\n",
                "        return model\n",
                "    \n",
                "    @staticmethod\n",
                "    def from_pretrained():\n",
                "        if not os.path.exists(f\"{DATA_DIR}/neural_relevance.pt\"):\n",
                "            url = \"https://huggingface.co/Etto48/MIRProject/resolve/main/neural_relevance.pt\"\n",
                "            weights_request = requests.get(url)\n",
                "            weights_request.raise_for_status()\n",
                "            with tqdm(total=int(weights_request.headers[\"Content-Length\"]), unit=\"B\", unit_scale=True, desc=\"Downloading weights\") as pbar:\n",
                "                with open(f\"{DATA_DIR}/neural_relevance.pt\", \"wb\") as f:\n",
                "                    for chunk in weights_request.iter_content(chunk_size=1024):\n",
                "                        f.write(chunk)\n",
                "                        pbar.update(len(chunk))\n",
                "        model = NeuralRelevance.load(f\"{DATA_DIR}/neural_relevance.pt\")\n",
                "        return model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.impls.neural_scoring_function ===\n",
                "\n",
                "import numpy as np\n",
                "# import torch\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# from mir import DATA_DIR\n",
                "# from mir.neural_relevance.model import NeuralRelevance\n",
                "# from mir.ir.document_info import DocumentInfo\n",
                "# from mir.ir.posting import Posting\n",
                "# from mir.ir.scoring_function import ScoringFunction\n",
                "# from mir.ir.term import Term\n",
                "# from mir.neural_relevance.dataset import MSMarcoDataset\n",
                "\n",
                "\n",
                "class NeuralScoringFunction(ScoringFunction):\n",
                "    def __init__(self):\n",
                "        # Load the model\n",
                "        self.model = NeuralRelevance.from_pretrained()\n",
                "        self.model.eval()\n",
                "\n",
                "    def __call__(self, document: DocumentInfo, postings: list[Posting], query: list[Term], *, document_content: str, query_content: str, **kwargs) -> float:\n",
                "        if len(document_content) == 0 or len(query_content) == 0:\n",
                "            return 0.0\n",
                "        with torch.no_grad():\n",
                "            score = self.model.forward_queries_and_documents([query_content], [document_content])\n",
                "        return score.item()\n",
                "    \n",
                "    def batched_call(self, document_contents: list[str], query_contents: str) -> list[float]:\n",
                "        scores = []\n",
                "        with torch.no_grad():\n",
                "            scores = self.model.forward_queries_and_documents([query_contents]*len(document_contents), document_contents)\n",
                "        return scores.tolist()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.impls.sqlite_index ===\n",
                "\n",
                "from collections.abc import Generator\n",
                "# import os\n",
                "import sqlite3\n",
                "import sys\n",
                "from typing import Any, Optional\n",
                "\n",
                "import psutil\n",
                "# from mir.ir.document_info import DocumentInfo\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.impls.default_tokenizers import DefaultTokenizer\n",
                "# from mir.ir.index import Index\n",
                "# from mir.ir.posting import Posting\n",
                "# from mir.ir.term import Term\n",
                "# from mir.ir.token_ir import TokenLocation\n",
                "# from mir.ir.tokenizer import Tokenizer\n",
                "\n",
                "\n",
                "class SqliteIndex(Index):\n",
                "    def __init__(self, path: Optional[str] = None):\n",
                "        super().__init__()\n",
                "\n",
                "        self.connection = sqlite3.connect(\n",
                "            path if path is not None else \":memory:\", \n",
                "            check_same_thread=False, \n",
                "            cached_statements=1024,)\n",
                "        \n",
                "        assert sys.version_info.major == 3, \"Python 2 is not supported\"\n",
                "        assert sys.version_info.minor >= 10, \"Python <3.10 is not supported\"\n",
                "        \n",
                "        legacy_mode = sys.version_info.minor == 10\n",
                "        if legacy_mode:\n",
                "            self.isolation_level = None\n",
                "        else:\n",
                "            self.connection.autocommit = True\n",
                "        \n",
                "        self.connection.execute(\"pragma synchronous = off\")\n",
                "        self.connection.execute(f\"pragma threads = {os.cpu_count()}\")\n",
                "        self.connection.execute(\"pragma journal_mode = WAL\")\n",
                "        cache_memory = psutil.virtual_memory().total // 1024 // 2\n",
                "        self.connection.execute(f\"pragma cache_size = {-cache_memory}\")\n",
                "        self.connection.execute(f\"pragma mmap_size = {1024*1024*1024 * 16}\")\n",
                "        self.connection.execute(\"pragma temp_store = memory\")\n",
                "\n",
                "        if legacy_mode:\n",
                "            self.connection.isolation_level = \"DEFERRED\"\n",
                "        else:\n",
                "            self.connection.autocommit = False\n",
                "\n",
                "\n",
                "        self.connection.execute(\n",
                "            \"create table if not exists postings \"\n",
                "            \"(term_id integer references terms(term_id) not null, \"\n",
                "            \"doc_id integer references document_info(doc_id) not null, \"\n",
                "            \"occurrences_author integer not null, \"\n",
                "            \"occurrences_title integer not null, \"\n",
                "            \"occurrences_body integer not null, \"\n",
                "            \"primary key (term_id, doc_id))\")\n",
                "        self.connection.execute(\n",
                "            \"create table if not exists document_info \"\n",
                "            \"(doc_id integer not null primary key autoincrement, \"\n",
                "            \"author_len integer not null, \"\n",
                "            \"title_len integer not null, \"\n",
                "            \"body_len integer not null)\")\n",
                "        self.connection.execute(\n",
                "            \"create table if not exists document_contents \"\n",
                "            \"(doc_id integer not null primary key references document_info(doc_id), \"\n",
                "            \"author text, \"\n",
                "            \"title text, \"\n",
                "            \"body text)\")\n",
                "        self.connection.execute(\n",
                "            \"create table if not exists terms \"\n",
                "            \"(term_id integer not null primary key autoincrement, \"\n",
                "            \"term text unique not null, \"\n",
                "            \"document_frequency integer not null)\")\n",
                "        \n",
                "        self.connection.execute(\"create table if not exists global_info (key text not null primary key, value integer)\")\n",
                "        # add global info default values if not present\n",
                "        self.connection.execute(\"insert or ignore into global_info values ('total_author_len', 0)\")\n",
                "        self.connection.execute(\"insert or ignore into global_info values ('total_title_len', 0)\")\n",
                "        self.connection.execute(\"insert or ignore into global_info values ('total_body_len', 0)\")\n",
                "        self.connection.execute(\"insert or ignore into global_info values ('num_docs', 0)\")\n",
                "\n",
                "        self.connection.execute(\"pragma optimize\")\n",
                "\n",
                "        self.connection.commit()\n",
                "        self.global_info_dirty = True \n",
                "        self.cached_global_info = None\n",
                "    \n",
                "    def get_postings(self, term_id: int) -> Generator[Posting, None, None]:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\n",
                "            \"select doc_id, occurrences_author, occurrences_title, occurrences_body from postings where term_id = ? \"\n",
                "            \"order by doc_id\", (term_id,))\n",
                "        def row_factory(_cursor, row):\n",
                "            return Posting(row[0], term_id, {\"author\": row[1], \"title\": row[2], \"body\": row[3]})\n",
                "        cursor.row_factory = row_factory\n",
                "        yield from cursor\n",
                "\n",
                "    def get_document_info(self, doc_id: int) -> DocumentInfo:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select author_len, title_len, body_len from document_info where doc_id = ?\", (doc_id,))\n",
                "        author_len, title_len, body_len = cursor.fetchone()\n",
                "        return DocumentInfo(doc_id, [author_len, title_len, body_len])\n",
                "    \n",
                "    def get_document_contents(self, doc_id: int) -> DocumentContents:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select author, title, body from document_contents where doc_id = ?\", (doc_id,))\n",
                "        author, title, body = cursor.fetchone()\n",
                "        return DocumentContents(author, title, body)\n",
                "\n",
                "    def get_term(self, term_id: int) -> Term:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select term, document_frequency from terms where term_id = ?\", (term_id,))\n",
                "        term, document_frequency = cursor.fetchone()\n",
                "        return Term(term, term_id, document_frequency=document_frequency)\n",
                "\n",
                "    def get_term_id(self, term: str) -> Optional[int]:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select term_id from terms where term = ?\", (term,))\n",
                "        result = cursor.fetchone()\n",
                "        return result[0] if result is not None else None\n",
                "    \n",
                "    def get_global_info(self) -> dict[str, Any]:\n",
                "        if self.global_info_dirty:\n",
                "            cursor = self.connection.cursor()\n",
                "            cursor.execute(\"select key, value from global_info\")\n",
                "            global_info = cursor.fetchall()\n",
                "            global_info = {key: value for key, value in global_info}\n",
                "            self.cached_global_info = {\n",
                "                \"avg_field_lengths\": {\n",
                "                    \"author\": global_info[\"total_author_len\"] / global_info[\"num_docs\"],\n",
                "                    \"title\": global_info[\"total_title_len\"] / global_info[\"num_docs\"],\n",
                "                    \"body\": global_info[\"total_body_len\"] / global_info[\"num_docs\"]\n",
                "                },\n",
                "                \"num_docs\": global_info[\"num_docs\"]\n",
                "            }\n",
                "            self.global_info_dirty = False\n",
                "        return self.cached_global_info\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select value from global_info where key = 'num_docs'\")\n",
                "        return cursor.fetchone()[0]\n",
                "\n",
                "    def _increment_field_lengths(self, author_len: int, title_len: int, body_len: int) -> None:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"update global_info set value = value + ? where key = 'total_author_len'\", (author_len,))\n",
                "        cursor.execute(\"update global_info set value = value + ? where key = 'total_title_len'\", (title_len,))\n",
                "        cursor.execute(\"update global_info set value = value + ? where key = 'total_body_len'\", (body_len,))\n",
                "\n",
                "    def _create_or_get_term_id(self, term: str) -> int:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"insert or ignore into terms(term, document_frequency) values (?, 0)\", (term,))\n",
                "        cursor.execute(\"select term_id from terms where term = ?\", (term,))\n",
                "        return cursor.fetchone()[0]\n",
                "\n",
                "    def _new_document(self, doc: DocumentContents, author_len: int, title_len: int, body_len: int) -> int:\n",
                "        cursor = self.connection.cursor()\n",
                "        if doc.__dict__.get(\"doc_id\") is not None:\n",
                "            cursor.execute(\"insert into document_info(doc_id, author_len, title_len, body_len) values (?, ?, ?, ?)\", (doc.doc_id, author_len, title_len, body_len))\n",
                "        else:\n",
                "            cursor.execute(\"insert into document_info(author_len, title_len, body_len) values (?, ?, ?)\", (author_len, title_len, body_len))\n",
                "        doc_id = cursor.lastrowid\n",
                "        cursor.execute(\"insert into document_contents(doc_id, author, title, body) values (?, ?, ?, ?)\", (doc_id, doc.author, doc.title, doc.body))\n",
                "        cursor.execute(\"update global_info set value = value + 1 where key = 'num_docs'\")\n",
                "        return doc_id\n",
                "\n",
                "    def _update_postings(self, term_id: int, doc_id: int, location: TokenLocation) -> None:\n",
                "        increments = {\n",
                "            \"author\": 1 if location == TokenLocation.AUTHOR else 0, \n",
                "            \"title\": 1 if location == TokenLocation.TITLE else 0, \n",
                "            \"body\": 1 if location == TokenLocation.BODY else 0\n",
                "        }\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select occurrences_author, occurrences_title, occurrences_body from postings where term_id = ? and doc_id = ?\", (term_id, doc_id))\n",
                "        result = cursor.fetchone()\n",
                "        if result is None:\n",
                "            cursor.execute(\n",
                "                \"insert into postings(term_id, doc_id, occurrences_author, occurrences_title, occurrences_body) \"\n",
                "                \"values (?, ?, ?, ?, ?)\", (term_id, doc_id, increments[\"author\"], increments[\"title\"], increments[\"body\"]))\n",
                "        else:\n",
                "            cursor.execute(\n",
                "                \"update postings set occurrences_author = occurrences_author + ?, occurrences_title = occurrences_title + ?, \"\n",
                "                \"occurrences_body = occurrences_body + ? where term_id = ? and doc_id = ?\",\n",
                "                (increments[\"author\"], increments[\"title\"], increments[\"body\"], term_id, doc_id))\n",
                "\n",
                "    def _contains_document(self, doc_id: int) -> bool:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"select count(*) from document_info where doc_id = ?\", (doc_id,))\n",
                "        ret = cursor.fetchone()[0]\n",
                "        return ret > 0\n",
                "\n",
                "    def _increment_document_frequency(self, term_id: int) -> None:\n",
                "        cursor = self.connection.cursor()\n",
                "        cursor.execute(\"update terms set document_frequency = document_frequency + 1 where term_id = ?\", (term_id,))\n",
                "\n",
                "    def index_document(self, doc: DocumentContents, tokenizer: Tokenizer) -> None:\n",
                "\n",
                "        if doc.__dict__.get(\"doc_id\") is not None:\n",
                "            if self._contains_document(doc.doc_id):\n",
                "                return\n",
                "        self.global_info_dirty = True\n",
                "\n",
                "        terms = tokenizer.tokenize_document(doc)\n",
                "        author_length = sum(1 for term in terms if term.location == TokenLocation.AUTHOR)\n",
                "        title_length = sum(1 for term in terms if term.location == TokenLocation.TITLE)\n",
                "        body_length = sum(1 for term in terms if term.location == TokenLocation.BODY)\n",
                "        \n",
                "        self._increment_field_lengths(author_length, title_length, body_length)\n",
                "\n",
                "        encountered_terms = set()\n",
                "        term_ids_and_locations = []\n",
                "        for term in terms:\n",
                "            term_id = self._create_or_get_term_id(term.text)\n",
                "            if term_id not in encountered_terms:\n",
                "                self._increment_document_frequency(term_id)\n",
                "            encountered_terms.add(term_id)\n",
                "            term_ids_and_locations.append((term_id, term.location))\n",
                "        doc_id = self._new_document(doc, author_length, title_length, body_length)\n",
                "        for term_id, location in term_ids_and_locations:\n",
                "            self._update_postings(term_id, doc_id, location)\n",
                "        self.connection.commit()\n",
                "\n",
                "    def bulk_index_documents(self, docs, tokenizer, verbose = False):\n",
                "        super().bulk_index_documents(docs, tokenizer, verbose)\n",
                "        self.connection.execute(\"pragma optimize\")\n",
                "        self.connection.commit()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.priority_queue ===\n",
                "\n",
                "import heapq\n",
                "from typing import Iterable, Optional, Sized\n",
                "\n",
                "class PriorityQueue(Iterable[tuple[float, int]], Sized):\n",
                "    def __init__(self, max_size: int):\n",
                "        \"\"\"\n",
                "        Create a priority queue with a maximum size.\n",
                "        \"\"\"\n",
                "        self.heap = []\n",
                "        self.finalised = False\n",
                "        self.max_size = max_size\n",
                "    \n",
                "    def push(self, doc_id: int, score: float) -> Optional[int]:\n",
                "        \"\"\"\n",
                "        Add an item with a given score to the priority queue\n",
                "\n",
                "        Returns the doc_id of the item that was popped, if any. If the new item was not added returns its doc_id.\n",
                "        \"\"\"\n",
                "        if len(self) == self.max_size:\n",
                "            if score > self.heap[0][0]:\n",
                "                popped = heapq.heappushpop(self.heap, (score, doc_id))\n",
                "                return popped[1]\n",
                "            else:\n",
                "                return doc_id\n",
                "        else:\n",
                "            heapq.heappush(self.heap, (score, doc_id))\n",
                "            return None\n",
                "    \n",
                "    def finalise(self):\n",
                "        \"\"\"\n",
                "        Call this after all items have been pushed to the priority queue.\n",
                "        \"\"\"\n",
                "        self.heap.sort(reverse=True)\n",
                "        self.finalised = True\n",
                "    \n",
                "    def __iter__(self) -> Iterable[tuple[float, int]]:\n",
                "        \"\"\"\n",
                "        Iterate over the items in the priority queue.\n",
                "        \"\"\"\n",
                "        if not self.finalised:\n",
                "            raise ValueError(\"Priority queue must be finalised before iterating\")\n",
                "        return iter(self.heap)\n",
                "    \n",
                "    def __len__(self) -> int:\n",
                "        \"\"\"\n",
                "        Get the number of items in the priority queue.\n",
                "        \"\"\"\n",
                "        return len(self.heap)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Ir system\n",
                "\n",
                "This class is the core of the project. All the components of the system are needed in order to construct an instance of this class.\n",
                "It uses the components to perform the indexing and search operations.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.ir.ir ===\n",
                "\n",
                "from collections.abc import Generator\n",
                "# import string\n",
                "import time\n",
                "from typing import Optional\n",
                "\n",
                "# import pandas as pd\n",
                "from tqdm.auto import tqdm\n",
                "from more_itertools import peekable\n",
                "\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.ir.impls.default_index import DefaultIndex\n",
                "# from mir.ir.impls.count_scoring_function import CountScoringFunction\n",
                "# from mir.ir.impls.default_tokenizers import DefaultTokenizer\n",
                "# from mir.ir.index import Index\n",
                "# from mir.ir.priority_queue import PriorityQueue\n",
                "# from mir.ir.scoring_function import ScoringFunction\n",
                "# from mir.ir.tokenizer import Tokenizer\n",
                "# from mir.utils.sized_generator import SizedGenerator\n",
                "\n",
                "class Ir:\n",
                "    def __init__(self, index: Optional[Index] = None, tokenizer: Optional[Tokenizer] = None, scoring_functions: Optional[list[tuple[int, ScoringFunction]]] = None):\n",
                "        \"\"\"\n",
                "        Create an IR system.\n",
                "\n",
                "        # Parameters\n",
                "        - index (Index): The index to use. If None, a DefaultIndex is used.\n",
                "        - tokenizer (Tokenizer): The tokenizer to use. If None, a DefaultTokenizer is used.\n",
                "        - scoring_functions (Optional[list[tuple[int, ScoringFunction]]]): A list of scoring functions to use, with their respective top_k results to keep.\n",
                "        If None CountScoringFunction is used.\n",
                "        \"\"\"\n",
                "        self.index: Index = index if index is not None else DefaultIndex()\n",
                "        self.tokenizer: Tokenizer = tokenizer if tokenizer is not None else DefaultTokenizer()\n",
                "        self.scoring_functions: list[tuple[int, ScoringFunction]] = scoring_functions if scoring_functions is not None else [\n",
                "            (1000, CountScoringFunction())\n",
                "        ]\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        \"\"\"\n",
                "        Get the number of documents in the index.\n",
                "        \"\"\"\n",
                "        return len(self.index)\n",
                "\n",
                "    def index_document(self, doc: DocumentContents) -> None:\n",
                "        \"\"\"\n",
                "        Index a document.\n",
                "\n",
                "        # Parameters\n",
                "        - doc (DocumentContents): The document to index.\n",
                "        \"\"\"\n",
                "        self.index.index_document(doc, self.tokenizer)\n",
                "\n",
                "    def bulk_index_documents(self, docs: SizedGenerator[DocumentContents, None, None], verbose: bool = False) -> None:\n",
                "        \"\"\"\n",
                "        Bulk index documents.\n",
                "\n",
                "        # Parameters\n",
                "        - docs (SizedGenerator[DocumentContents, None, None]): A generator of documents to index.\n",
                "        - verbose (bool): Whether to show a progress bar.\n",
                "        \"\"\"\n",
                "        self.index.bulk_index_documents(docs, self.tokenizer, verbose)\n",
                "\n",
                "    def search(self, query: str) -> Generator[DocumentContents, None, None]:\n",
                "        \"\"\"\n",
                "        Search for documents based on a query.\n",
                "        Uses document-at-a-time scoring.\n",
                "\n",
                "        # Parameters\n",
                "        - query (str): The query to search for.\n",
                "        - scoring_functions (list[ScoringFunction]): A list of scoring functions to use.\n",
                "\n",
                "        # Yields\n",
                "        - DocumentContents: A document that matches the query. In decreasing order of score.\n",
                "        It also has a score attribute with the score of the document.\n",
                "        \"\"\"\n",
                "\n",
                "        assert len(self.scoring_functions) > 0, \"At least one scoring function must be provided\"\n",
                "\n",
                "        ks, scoring_functions = zip(*self.scoring_functions)\n",
                "        scoring_functions: list[ScoringFunction] = list(scoring_functions)\n",
                "        ks: list[int] = list(ks)[::-1]\n",
                "        \n",
                "        terms = self.tokenizer.tokenize_query(query)\n",
                "        term_ids = [term_id for term in terms if (\n",
                "            term_id := self.index.get_term_id(term.text)) is not None]\n",
                "        terms = [self.index.get_term(term_id) for term_id in term_ids]\n",
                "        posting_generators = [\n",
                "            peekable(self.index.get_postings(term_id)) for term_id in term_ids]\n",
                "\n",
                "        priority_queue = PriorityQueue(ks[-1])\n",
                "        first_scoring_function = scoring_functions[0]\n",
                "        postings_cache = {}\n",
                "\n",
                "        while True:\n",
                "            # find the lowest doc_id among all the posting lists\n",
                "            # doing this avoids having to iterate over all the doc_ids\n",
                "            # we only take into account the doc_ids that are present in the posting lists\n",
                "            lowest_doc_id = None\n",
                "            empty_posting_lists = []\n",
                "            for i, posting in enumerate(posting_generators):\n",
                "                try:\n",
                "                    doc_id = posting.peek().doc_id\n",
                "                    if lowest_doc_id is None or doc_id < lowest_doc_id:\n",
                "                        lowest_doc_id = doc_id\n",
                "                except StopIteration:\n",
                "                    empty_posting_lists.append(i)\n",
                "            # all the posting lists are empty\n",
                "            if lowest_doc_id is None:\n",
                "                break\n",
                "\n",
                "            # remove the empty posting lists\n",
                "            for i in reversed(empty_posting_lists):\n",
                "                posting_generators.pop(i)\n",
                "                term_ids.pop(i)\n",
                "\n",
                "            postings = []\n",
                "            # get all the postings with the current doc_id, and advance their iterators\n",
                "            for i, posting in enumerate(posting_generators):\n",
                "                if posting.peek().doc_id == lowest_doc_id:\n",
                "                    next_posting = next(posting)\n",
                "                    postings.append(next_posting)\n",
                "            postings_cache[lowest_doc_id] = postings\n",
                "            # now that we have all the info about the current document, we can score it\n",
                "            global_info = self.index.get_global_info()\n",
                "            document_info = self.index.get_document_info(lowest_doc_id)\n",
                "            score = first_scoring_function(document_info, postings, terms, **global_info)\n",
                "            # we add the score and doc_id to the priority queue\n",
                "            popped_doc_id = priority_queue.push(lowest_doc_id, score)\n",
                "            # if the priority queue is full, we remove the lowest score\n",
                "            if popped_doc_id is not None:\n",
                "                del postings_cache[popped_doc_id]\n",
                "        \n",
                "        priority_queue.finalise()\n",
                "\n",
                "        for scoring_function in scoring_functions[1:]:\n",
                "            ks.pop()\n",
                "            resorted_documents = []\n",
                "            if scoring_function.batched_call is not None:\n",
                "                scores: list[float] = scoring_function.batched_call(\n",
                "                    [self.index.get_document_contents(doc_id).body for _, doc_id in priority_queue.heap[:ks[-1]]],\n",
                "                    query\n",
                "                )\n",
                "                for i, (score, doc_id) in enumerate(priority_queue.heap[:ks[-1]]):\n",
                "                    new_score = scores[i]\n",
                "                    resorted_documents.append((new_score + score, doc_id))\n",
                "            else:\n",
                "                for score, doc_id in priority_queue.heap[:ks[-1]]:\n",
                "                    postings = postings_cache[doc_id]\n",
                "                    global_info = self.index.get_global_info()\n",
                "                    global_info[\"document_content\"] = self.index.get_document_contents(doc_id).body\n",
                "                    global_info[\"query_content\"] = query\n",
                "                    new_score = scoring_function(self.index.get_document_info(doc_id), postings, terms, **global_info)\n",
                "                    # we add the old score to maintain monotonicity\n",
                "                    resorted_documents.append((new_score + score, doc_id))\n",
                "            \n",
                "            resorted_documents.sort(key=lambda x: x[0], reverse=True)\n",
                "            priority_queue.heap = resorted_documents + priority_queue.heap[ks[-1]:]\n",
                "\n",
                "        for score, doc_id in priority_queue:\n",
                "            ret = self.index.get_document_contents(doc_id)\n",
                "            ret.add_field(\"id\", doc_id)\n",
                "            ret.set_score(score)\n",
                "            yield ret\n",
                "\n",
                "    def get_run(self, queries: pd.DataFrame, verbose: bool = False, pyterrier_compatible: bool = False) -> pd.DataFrame:\n",
                "        \"\"\"\n",
                "        Generate a run file for the given queries in the form of a pandas DataFrame.\n",
                "        You can encode it to a file using a tab separator and the to_csv method.\n",
                "\n",
                "        # Parameters\n",
                "        - queries (pd.DataFrame): A DataFrame with the queries to run. \n",
                "        It must have the columns \"query_id\" and \"text\".\n",
                "        - verbose (bool): Whether to show a progress bar.\n",
                "\n",
                "        # Returns\n",
                "        - pd.DataFrame: The run file. It has the columns \n",
                "        \"query_id\", \"Q0\", \"document_no\", \"rank\", \"score\", \"run_id\".\n",
                "        If pyterrier_compatible is True, the columns are \"qid\", \"docid\", \"docno\", \"rank\", \"score\", \"query\".\n",
                "        \"\"\"\n",
                "        \n",
                "        run = []\n",
                "        for _, query_row in tqdm(queries.iterrows(), desc=\"Running queries\", disable=not verbose, total=len(queries)):\n",
                "            query_id = query_row[\"query_id\"]\n",
                "            query = query_row[\"text\"]\n",
                "            for rank, doc in enumerate(self.search(query), start=0):\n",
                "                if pyterrier_compatible:\n",
                "                    run.append(\n",
                "                        {\"qid\": query_id, \"docid\": doc.id, \"docno\": doc.id, \"rank\": rank, \"score\": doc.score, \"query\": query})\n",
                "                else:\n",
                "                    run.append(\n",
                "                        {\"query_id\": query_id, \"Q0\": \"Q0\", \"doc_id\": doc.id, \"rank\": rank, \"score\": doc.score, \"run_id\": self.__class__.__name__})\n",
                "\n",
                "        run = pd.DataFrame(run)\n",
                "        return run\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.utils.dataset ===\n",
                "\n",
                "from collections.abc import Generator\n",
                "import gzip\n",
                "import tarfile\n",
                "# import numpy as np\n",
                "# import requests\n",
                "# from mir import DATA_DIR, COLAB\n",
                "# import pandas as pd\n",
                "# import os\n",
                "import json\n",
                "# import unidecode\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# from mir.ir.document_contents import DocumentContents\n",
                "# from mir.utils.sized_generator import SizedGenerator\n",
                "\n",
                "def get_msmarco_dataset(verbose: bool = False):\n",
                "    \"\"\"\n",
                "    Downloads the MS MARCO dataset to the data directory.\n",
                "    \"\"\"\n",
                "    corpus = \"https://msmarco.z22.web.core.windows.net/msmarcoranking/collection.tar.gz\"\n",
                "    queries = \"https://msmarco.z22.web.core.windows.net/msmarcoranking/queries.tar.gz\"\n",
                "    queries_valid = \"https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz\"\n",
                "    queries_test = \"https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2020-queries.tsv.gz\"\n",
                "    qrels_train = \"https://msmarco.z22.web.core.windows.net/msmarcoranking/qrels.train.tsv\"\n",
                "    # trec link is usually down so I'm using my own link to the same files\n",
                "    # qrels_valid = \"https://trec.nist.gov/data/deep/2019qrels-pass.txt\"\n",
                "    # qrels_test = \"https://trec.nist.gov/data/deep/2020qrels-pass.txt\"\n",
                "    qrels_valid = \"https://huggingface.co/Etto48/MIRProject/resolve/main/2019qrels-pass.txt\"\n",
                "    qrels_test = \"https://huggingface.co/Etto48/MIRProject/resolve/main/2020qrels-pass.txt\"\n",
                "    \n",
                "    urls = [corpus, queries, queries_valid, queries_test, qrels_train, qrels_valid, qrels_test]\n",
                "    dataset_dir = f\"{DATA_DIR}/msmarco\"\n",
                "    os.makedirs(dataset_dir, exist_ok=True)\n",
                "    for url in urls:\n",
                "        file_name = url.split(\"/\")[-1]\n",
                "        path = f\"{dataset_dir}/{file_name}\"\n",
                "        if not os.path.exists(path):\n",
                "            response = requests.get(url, stream=True)\n",
                "            response.raise_for_status()\n",
                "            file_size = int(response.headers.get(\"content-length\", 0))\n",
                "            block_size = 1024\n",
                "            try:\n",
                "                with tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=f\"Downloading {file_name}\", disable=not verbose) as pbar:\n",
                "                    with open(path, \"wb\") as f:\n",
                "                        for data in response.iter_content(block_size):\n",
                "                            f.write(data)\n",
                "                            pbar.update(len(data))\n",
                "            except (KeyboardInterrupt, Exception) as e:\n",
                "                os.remove(path)\n",
                "                raise e\n",
                "        decompressed_path = path.replace(\".tar.gz\", \"\")\n",
                "        decompressed_path = decompressed_path.replace(\".gz\", \"\")\n",
                "        if file_name.endswith(\".tar.gz\") and not os.path.exists(f\"{decompressed_path}.tsv\"):\n",
                "            if verbose:\n",
                "                print(f\"Decompressing {file_name}...\")\n",
                "            with tarfile.open(path, \"r:gz\") as tar:\n",
                "                tar.extractall(dataset_dir, filter=\"fully_trusted\")\n",
                "        elif not file_name.endswith(\".tar.gz\") and \\\n",
                "                file_name.endswith(\".gz\") and \\\n",
                "                not os.path.exists(decompressed_path):\n",
                "            if verbose:\n",
                "                print(f\"Decompressing {file_name}...\")\n",
                "            with gzip.open(path, \"rb\") as f_in:\n",
                "                with open(decompressed_path, \"wb\") as f_out:\n",
                "                    f_out.write(f_in.read())\n",
                "\n",
                "def msmarco_dataset_to_contents(corpus: pd.DataFrame, verbose: bool = False) -> SizedGenerator[DocumentContents, None, None]:\n",
                "    \"\"\"\n",
                "    Returns the number of documents and a generator of DocumentContents from the test corpus.\n",
                "    \"\"\"\n",
                "    def inner() -> Generator[DocumentContents, None, None]:\n",
                "        for _, row in corpus.iterrows():\n",
                "            yield DocumentContents(author=\"\", title=\"\", body=row['text'], doc_id=int(row['docno']))\n",
                "    return SizedGenerator(inner(), len(corpus))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "#%% === mir.utils.download_and_extract ===\n",
                "\n",
                "# import os\n",
                "# import tarfile\n",
                "# import requests\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "def download_and_extract(url: str, path: str, desc: str = \"\"):\n",
                "    stream = requests.get(url, stream=True)\n",
                "    total_size = int(stream.headers.get('content-length', 0))\n",
                "    tgz_path = f\"{path}.tar.gz\"\n",
                "    output_dir = f\"{path}\"\n",
                "    if not os.path.exists(tgz_path):\n",
                "        with tqdm(total=total_size, unit='B', unit_scale=True, unit_divisor=1024, desc=f\"Downloading {desc}\") as pbar:\n",
                "            with open(tgz_path, 'wb') as f:\n",
                "                for chunk in stream.iter_content(chunk_size=1024):\n",
                "                    f.write(chunk)\n",
                "                    pbar.update(len(chunk))\n",
                "    if not os.path.exists(output_dir):\n",
                "        with tarfile.open(tgz_path, 'r:gz') as tar:\n",
                "            members = tqdm(tar.getmembers(), desc=f\"Extracting {desc}\")\n",
                "            tar.extractall(output_dir, members)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Demo\n",
                "\n",
                "Now we will use the system to index ms-marco and run the test queries.\n",
                "Then we will compare the results with the ones of PyTerrier.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {
                "autoscroll": false,
                "collapsed": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Decompressing queries.tar.gz...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "473b85cc93274e118b5f5c44f66d5be0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading PyTerrier Index:   0%|          | 0.00/890M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[30], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m msmarco_sqlite_index_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/Etto48/MIRProject/resolve/main/msmarco-sqlite-index.db.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# download pyterrier index\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsmarco_pyterrier_index_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPyTerrier Index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# download sqlite index\u001b[39;00m\n\u001b[1;32m     27\u001b[0m download_and_extract(msmarco_sqlite_index_url, DATA_DIR, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQLite Index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[29], line 16\u001b[0m, in \u001b[0;36mdownload_and_extract\u001b[0;34m(url, path, desc)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_size, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tgz_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m     17\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     18\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
                        "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:576\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 576\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
                        "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:519\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    521\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[1;32m    522\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
                        "File \u001b[0;32m/usr/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
                        "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
                        "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "#%% === mir.scripts.demo ===\n",
                "\n",
                "# import os\n",
                "import re\n",
                "import pyterrier as pt\n",
                "from pyterrier import IndexFactory\n",
                "# import pandas as pd\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# from mir import DATA_DIR\n",
                "# from mir.ir.impls.bm25f_scoring import BM25FScoringFunction\n",
                "# from mir.ir.impls.neural_scoring_function import NeuralScoringFunction\n",
                "# from mir.ir.impls.sqlite_index import SqliteIndex\n",
                "# from mir.ir.ir import Ir\n",
                "# from mir.utils.dataset import get_msmarco_dataset, msmarco_dataset_to_contents\n",
                "# from mir.utils.download_and_extract import download_and_extract\n",
                "\n",
                "\n",
                "get_msmarco_dataset(verbose=True)\n",
                "dataset_csv = f\"{DATA_DIR}/msmarco/collection.tsv\"\n",
                "index_path = f\"{DATA_DIR}/msmarco-pyterrier-index/data.properties\"\n",
                "msmarco_pyterrier_index_url = \"https://huggingface.co/Etto48/MIRProject/resolve/main/msmarco-pyterrier-index.tar.gz\"\n",
                "msmarco_sqlite_index_url = \"https://huggingface.co/Etto48/MIRProject/resolve/main/msmarco-sqlite-index.db.tar.gz\"\n",
                "# download pyterrier index\n",
                "download_and_extract(msmarco_pyterrier_index_url, DATA_DIR, desc=\"PyTerrier Index\")\n",
                "# download sqlite index\n",
                "download_and_extract(msmarco_sqlite_index_url, DATA_DIR, desc=\"SQLite Index\")\n",
                "\n",
                "indexer = pt.terrier.IterDictIndexer(f\"{DATA_DIR}/msmarco-pyterrier-index\")\n",
                "if not os.path.exists(index_path):\n",
                "    dataset = pd.read_csv(dataset_csv, sep='\\t', header=None, names=['docno', 'text'], dtype={'docno': str, 'text': str})\n",
                "    indexref = indexer.index(tqdm(dataset.to_dict(orient='records'), desc=\"Indexing\"))\n",
                "    del dataset\n",
                "else:\n",
                "    indexref = pt.IndexRef.of(index_path)\n",
                "index = IndexFactory.of(indexref)\n",
                "\n",
                "\n",
                "topics_path = f\"{DATA_DIR}/msmarco/msmarco-test2020-queries.tsv\"\n",
                "qrels_path = f\"{DATA_DIR}/msmarco/2020qrels-pass.txt\"\n",
                "\n",
                "topics = pd.read_csv(topics_path, sep='\\t', header=None, names=['qid', 'query'], dtype={'qid': str, 'query': str})\n",
                "qrels = pd.read_csv(qrels_path, sep=' ', header=None, names=['qid', 'Q0', 'docno', 'relevance'], dtype={'qid': str, 'Q0': str, 'docno': str, 'relevance': int})\n",
                "\n",
                "def preprocess_query(query):\n",
                "    query = re.sub(r'[^\\w\\s]', '', query)\n",
                "    query = query.lower()\n",
                "    return query\n",
                "\n",
                "topics['query'] = topics['query'].apply(preprocess_query)\n",
                "\n",
                "my_ir = Ir(SqliteIndex(f\"{DATA_DIR}/msmarco-sqlite-index.db\"), scoring_functions=[\n",
                "    (100, BM25FScoringFunction(1.2, 0.8)),\n",
                "    (10, NeuralScoringFunction())\n",
                "])\n",
                "if len(my_ir.index) == 0:\n",
                "    dataset = pd.read_csv(dataset_csv, sep='\\t', header=None, names=['docno', 'text'], dtype={'docno': str, 'text': str})\n",
                "    sized_generator = msmarco_dataset_to_contents(dataset)\n",
                "    my_ir.bulk_index_documents(sized_generator, verbose=True)\n",
                "\n",
                "my_topics = pd.read_csv(topics_path, sep='\\t', header=None, names=['query_id', 'text'], dtype={'query_id': int, 'text': str})\n",
                "my_run = my_ir.get_run(my_topics, verbose=True, pyterrier_compatible=True)\n",
                "\n",
                "bm25 = pt.terrier.Retriever(index, wmodel=\"BM25\")\n",
                "dfree = pt.terrier.Retriever(index, wmodel=\"DFRee\")\n",
                "pyterrier_models = {\n",
                "    \"BM25\": bm25 % 100,\n",
                "    \"BM25+DFRee\": (bm25 % 100) >> dfree\n",
                "}\n",
                "pyterrier_runs = {}\n",
                "for model_name, model in pyterrier_models.items():\n",
                "    print(f\"Running PyTerrier {model_name}\")\n",
                "    pyterrier_runs[model_name] = model.transform(topics)\n",
                "\n",
                "test_runs = [my_run, *pyterrier_runs.values()]\n",
                "names = [\"MyIR\", *pyterrier_models.keys()]\n",
                "\n",
                "metrics = [\"map\", \"ndcg\", \"recip_rank\", \"P.10\", \"recall.10\", ]\n",
                "res = pt.Experiment(test_runs, topics, qrels, metrics, names=names)\n",
                "print(res)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
